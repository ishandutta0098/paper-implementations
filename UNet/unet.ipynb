{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTN8-MVaU07z"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def double_conv(in_c, out_c):\n",
        "  conv = nn.Sequential(\n",
        "      nn.Conv2d(in_c, out_c, kernel_size = 3),\n",
        "      nn.ReLU(inplace = True),\n",
        "      nn.Conv2d(out_c, out_c, kernel_size = 3),\n",
        "      nn.ReLU(inplace = True)\n",
        "  )\n",
        "\n",
        "  return conv\n",
        "\n",
        "def crop_img(tensor, target_tensor):\n",
        "  target_size = target_tensor.size()[2]\n",
        "  tensor_size = tensor.size()[2]\n",
        "\n",
        "  delta = tensor_size - target_size\n",
        "  delta = delta // 2\n",
        "\n",
        "  return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta]\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(UNet, self).__init__()\n",
        "\n",
        "    self.max_pool_2x2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    self.down_conv_1 = double_conv(1, 64)\n",
        "    self.down_conv_2 = double_conv(64, 128)\n",
        "    self.down_conv_3 = double_conv(128, 256)\n",
        "    self.down_conv_4 = double_conv(256, 512) \n",
        "    self.down_conv_5 = double_conv(512, 1024)\n",
        "\n",
        "    self.up_trans_1 = nn.ConvTranspose2d(in_channels = 1024, \n",
        "                                         out_channels = 512,\n",
        "                                         kernel_size = 2, \n",
        "                                         stride = 2)\n",
        "\n",
        "    self.up_conv_1 = double_conv(1024, 512)\n",
        "\n",
        "    self.up_trans_2 = nn.ConvTranspose2d(in_channels = 512, \n",
        "                                         out_channels = 256,\n",
        "                                         kernel_size = 2, \n",
        "                                         stride = 2)\n",
        "\n",
        "    self.up_conv_2 = double_conv(512, 256)\n",
        "\n",
        "    self.up_trans_3 = nn.ConvTranspose2d(in_channels = 256, \n",
        "                                         out_channels = 128,\n",
        "                                         kernel_size = 2, \n",
        "                                         stride = 2)\n",
        "\n",
        "    self.up_conv_3 = double_conv(256, 128)\n",
        "\n",
        "    self.up_trans_4 = nn.ConvTranspose2d(in_channels = 128, \n",
        "                                         out_channels = 64,\n",
        "                                         kernel_size = 2, \n",
        "                                         stride = 2)\n",
        "\n",
        "    self.up_conv_4 = double_conv(128, 64)\n",
        "\n",
        "    self.out = nn.Conv2d(in_channels = 64,\n",
        "                         out_channels = 2,\n",
        "                         kernel_size = 1)\n",
        "\n",
        "  def forward(self, image):\n",
        "    # Encoder\n",
        "    x1 = self.down_conv_1(image)  \n",
        "    x2 = self.max_pool_2x2(x1)\n",
        "    x3 = self.down_conv_2(x2) \n",
        "    x4 = self.max_pool_2x2(x3)\n",
        "    x5 = self.down_conv_3(x4) \n",
        "    x6 = self.max_pool_2x2(x5)\n",
        "    x7 = self.down_conv_4(x6) \n",
        "    x8 = self.max_pool_2x2(x7)\n",
        "    x9 = self.down_conv_5(x8)\n",
        "\n",
        "    # Decoder\n",
        "    x = self.up_trans_1(x9)\n",
        "    y = crop_img(x7, x)\n",
        "    x = self.up_conv_1(torch.cat([x, y], 1))\n",
        "\n",
        "    x = self.up_trans_2(x)\n",
        "    y = crop_img(x5, x)\n",
        "    x = self.up_conv_2(torch.cat([x, y], 1))\n",
        "\n",
        "    x = self.up_trans_3(x)\n",
        "    y = crop_img(x3, x)\n",
        "    x = self.up_conv_3(torch.cat([x, y], 1))\n",
        "\n",
        "    x = self.up_trans_4(x)\n",
        "    y = crop_img(x1, x)\n",
        "    x = self.up_conv_4(torch.cat([x, y], 1))\n",
        "\n",
        "    x = self.out(x)\n",
        "    print(x.size())\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7mMwlGLptKU",
        "outputId": "03e47936-4cf5-447a-a37d-ed4e5c2ad2c5"
      },
      "source": [
        "image = torch.rand((1, 1, 572, 572)) # batch_size x chanels x height x width\n",
        "model = UNet()\n",
        "print(model(image))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2, 388, 388])\n",
            "tensor([[[[-0.0117, -0.0122, -0.0130,  ..., -0.0149, -0.0132, -0.0152],\n",
            "          [-0.0123, -0.0137, -0.0150,  ..., -0.0154, -0.0135, -0.0152],\n",
            "          [-0.0111, -0.0157, -0.0116,  ..., -0.0160, -0.0154, -0.0157],\n",
            "          ...,\n",
            "          [-0.0097, -0.0130, -0.0162,  ..., -0.0125, -0.0156, -0.0133],\n",
            "          [-0.0160, -0.0163, -0.0147,  ..., -0.0103, -0.0166, -0.0137],\n",
            "          [-0.0129, -0.0144, -0.0131,  ..., -0.0161, -0.0119, -0.0155]],\n",
            "\n",
            "         [[ 0.0716,  0.0711,  0.0723,  ...,  0.0737,  0.0740,  0.0721],\n",
            "          [ 0.0749,  0.0732,  0.0697,  ...,  0.0725,  0.0724,  0.0723],\n",
            "          [ 0.0698,  0.0728,  0.0753,  ...,  0.0722,  0.0742,  0.0712],\n",
            "          ...,\n",
            "          [ 0.0749,  0.0709,  0.0726,  ...,  0.0720,  0.0754,  0.0732],\n",
            "          [ 0.0742,  0.0731,  0.0764,  ...,  0.0735,  0.0722,  0.0696],\n",
            "          [ 0.0694,  0.0740,  0.0741,  ...,  0.0738,  0.0693,  0.0705]]]],\n",
            "       grad_fn=<ThnnConv2DBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}